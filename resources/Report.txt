DESC : Word alignment for translation lexicon acquisition

IDEAS FOR IMPROVMENT
>- make the first ranking in the language providing the highest number of 'pivot words'
>- do ranking, re-ranking in both languages and then merge using harmonic mean : test r1 (harmonic mean : direct), r2(harmonic  mean : reverse), r(harmonic mean : r1, r2)
- keep a dictionary of cognates candidates (with their likelihood) for each word in the source corpus
- weight the POS tags : hypothesis of symetry of POS tags from one language to another <ATTENTION homonyms!>
- use a new scoring function with Jaccard-POSweight-cognateProbability-lengthSimilarity-suffixSimilarity
- use German as pivot language for the words discarded by the FR-EN dictionary : leo
- if we are sure of the quality of our dictionary : given w, a word to translate : if dictionary[w] is not empty THEN 
return that list as translation candidates ELSE look for translation candidates only in the unknown words set
IE : compute the context vectors only for unknown words w.r.t the bilingual dictionary
Underlying hypothesis : we never start a translation task from scratch, there is always a background knowlegde that we use. 
Even for a human, when you start, you learn by heart and only after you can infer answer for unknown items but it is then 
based on the knowledge you collected learning by heart

TODO
- Implementation/Import of functions :
* MAP
* Manhattan Distance
- Test Manhattan distance (and exp version) as similarity function

TO FIX :
- Put conditions on obvious transfuges eg words with digits : 
if the word to translate does not contain a digit then do not propose translations containing digits 
if the word to translate does contain a digit then propose only translations that contain that digit
- Normalization 
docétaxel : [week, follow, life] ranked first even after re-ranking
Idea : Remove noise in the traductions proposed by removing the moisy words (so frequent that their scores are not relevant)
Run all one time without ranking - Extract the X most frequent candidates - Re-run discarded these words (X<=top)
If we don't have a test set, use the N least frequent words in source corpus as test set to perform the extraction
------------------------------------------------------------

SUBJECT=Alignement de chaînes et de textes

GOAL=Implement automatic traduction from french into english

WORK TO DO
CM1-1/ Identifier les transfuges et les cognats présents dans le corpus comparable
CM1-2/ Evaluation du travail effectué
CM1-2/a- Nombre de transfuges et de cognats identifiés
CM1-2/b- Qualité des transfuges et des cognats identifiés : precision, recall, F-measure 2PR/(P+R) {good: 1, bad:0)
OK> PROJET-A/ Implémenter la méthode directe
>PROJET-B/ Proposer une amélioration de la méthode directe

FORMULES
- Indice de ressemblance CM1,17 (Débili and Sammouda, 1992)
- Degré de comparabilité d’un corpus comparable CM2,9

NOTIONS UTILES 
- Genre
-Type de discours
- Méthode directe : CM2,10 "You shall know a word by the company it keeps" Firth (1957)

DEFINITIONS
- alignement de textes : mettre en correspondance automatiquement des
unités aux sens identiques à travers l’exploitation de corpus monolingues ou bilingues
=> Applications : traduction automatique, aide à la ~, RI monolingue et multi-lingue, extraction de lexiques
- corpus : ensemble de documents présentant une certaine homogénéité (période, langue parlée ou écrite, genre, type de discours,...)
=> type : { monolingues, bilingues {parallèles, comparables}, multimodaux }
"bilingues parallèles" = textes en relation de traduction 
"bilingues comparables" = pas de relation de traduction mais les textes abordent une même thématique sur une même période : ils sont 'comparables'
"multimodaux" = constitués de documents de nature différentes : texte électronique, texte manuscrit, parole, vidéo

- Indices d'alignement : {transfuges, cognats}
* cognats = {
véritables cognats : reconnaissance (FR) et recognition (EN)
faux amis : blesser (EN) et bless (EN)
cognats partiels dépendant du contexte : facteur (FR) et factor/mailman (EN)
cognats génétiques partageant des origines communes : chef (FR) et head (EN)
mots non reliés : glace (FR) et ice (EN)
}

- degré de comparabilité d’un corpus comparable P = l'espérance de trouver la traduction d’un mot du vocabulaire source (respectivement cible) dans le vocabulaire cible (respectivement source) étant donné un dictionnaire bilingue
